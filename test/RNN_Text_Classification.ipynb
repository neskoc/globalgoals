{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inc import stop_words as sw\n",
    "from inc import extra_stopwords as esw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "table_name = 'Training_set'\n",
    "db_path = 'db/training.sqlite'\n",
    "db_path = 'sqlite:///' + db_path\n",
    "engine = create_engine(db_path, echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-16 18:47:42,290 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-12-16 18:47:42,291 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,292 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-12-16 18:47:42,293 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,295 INFO sqlalchemy.engine.base.Engine SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "2020-12-16 18:47:42,295 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,297 INFO sqlalchemy.engine.base.Engine SELECT name FROM sqlite_master WHERE type='view' ORDER BY name\n",
      "2020-12-16 18:47:42,298 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,300 INFO sqlalchemy.engine.base.Engine PRAGMA main.table_xinfo(\"Training_set\")\n",
      "2020-12-16 18:47:42,301 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,302 INFO sqlalchemy.engine.base.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type = 'table'\n",
      "2020-12-16 18:47:42,303 INFO sqlalchemy.engine.base.Engine ('Training_set',)\n",
      "2020-12-16 18:47:42,305 INFO sqlalchemy.engine.base.Engine PRAGMA main.foreign_key_list(\"Training_set\")\n",
      "2020-12-16 18:47:42,305 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,306 INFO sqlalchemy.engine.base.Engine PRAGMA temp.foreign_key_list(\"Training_set\")\n",
      "2020-12-16 18:47:42,306 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,307 INFO sqlalchemy.engine.base.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type = 'table'\n",
      "2020-12-16 18:47:42,308 INFO sqlalchemy.engine.base.Engine ('Training_set',)\n",
      "2020-12-16 18:47:42,311 INFO sqlalchemy.engine.base.Engine PRAGMA main.index_list(\"Training_set\")\n",
      "2020-12-16 18:47:42,312 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,313 INFO sqlalchemy.engine.base.Engine PRAGMA main.index_info(\"ix_Training_set_index\")\n",
      "2020-12-16 18:47:42,314 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,316 INFO sqlalchemy.engine.base.Engine PRAGMA main.index_list(\"Training_set\")\n",
      "2020-12-16 18:47:42,317 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,318 INFO sqlalchemy.engine.base.Engine PRAGMA main.index_info(\"ix_Training_set_index\")\n",
      "2020-12-16 18:47:42,319 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 18:47:42,320 INFO sqlalchemy.engine.base.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type = 'table'\n",
      "2020-12-16 18:47:42,321 INFO sqlalchemy.engine.base.Engine ('Training_set',)\n",
      "2020-12-16 18:47:42,326 INFO sqlalchemy.engine.base.OptionEngine SELECT \"Training_set\".\"index\", \"Training_set\".abstract, \"Training_set\".class \n",
      "FROM \"Training_set\"\n",
      "2020-12-16 18:47:42,327 INFO sqlalchemy.engine.base.OptionEngine ()\n"
     ]
    }
   ],
   "source": [
    "training_data_df = pd.read_sql_table(table_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df = training_data_df.rename(columns={\"class\": \"label\"})\n",
    "training_data_df = training_data_df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstract    string\n",
       "label        Int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df = training_data_df.drop(columns=['index'])\n",
    "training_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequences(Dataset):\n",
    "    def __init__(self, df, max_seq_len):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        sw.STOP_WORDS = sw.STOP_WORDS.union(esw.common_stopwords)\n",
    "        sw.STOP_WORDS = sw.STOP_WORDS.union(esw.extra_stopwords)\n",
    "        vectorizer = CountVectorizer(stop_words=sw.STOP_WORDS, max_df=0.99, min_df=0.005)\n",
    "        vectorizer.fit(df.abstract.tolist())\n",
    "        \n",
    "        self.token2idx = vectorizer.vocabulary_\n",
    "        self.token2idx['<PAD>'] = max(self.token2idx.values()) + 1\n",
    "\n",
    "        tokenizer = vectorizer.build_analyzer()\n",
    "        self.encode = lambda x: [self.token2idx[token] for token in tokenizer(x)\n",
    "                                 if token in self.token2idx]\n",
    "        self.pad = lambda x: x + (max_seq_len - len(x)) * [self.token2idx['<PAD>']]\n",
    "        \n",
    "        sequences = [self.encode(sequence)[:max_seq_len] for sequence in df.abstract.tolist()]\n",
    "        sequences, self.labels = zip(*[(sequence, label) for sequence, label\n",
    "                                    in zip(sequences, df.label.tolist()) if sequence])\n",
    "        self.sequences = [self.pad(sequence) for sequence in sequences]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        assert len(self.sequences[i]) == self.max_seq_len\n",
    "        return self.sequences[i], self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Sequences(training_data_df, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2327"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    inputs = torch.LongTensor([item[0] for item in batch])\n",
    "    target = torch.FloatTensor([item[1] for item in batch])\n",
    "    return inputs, target\n",
    "\n",
    "batch_size = 2048\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        batch_size,\n",
    "        embedding_dimension=100,\n",
    "        hidden_size=128, \n",
    "        n_layers=1,\n",
    "        device='gpu',\n",
    "    ):\n",
    "        super(RNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_dimension)\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_dimension,\n",
    "            hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, 15)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.randn(self.n_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Avoid breaking if the last batch has a different size\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "            \n",
    "        encoded = self.encoder(inputs)\n",
    "        output, hidden = self.rnn(encoded, self.init_hidden())\n",
    "        output = self.decoder(output[:, :, -1]).squeeze()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (encoder): Embedding(2327, 100)\n",
       "  (rnn): GRU(100, 128, batch_first=True)\n",
       "  (decoder): Linear(in_features=128, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(\n",
    "    hidden_size=128,\n",
    "    vocab_size=len(dataset.token2idx),\n",
    "    device=device,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa3a859e96345838508f32a8ad886a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([1533])) must be the same as input size (torch.Size([1533, 15]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0df6a908449b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    630\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2580\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1533])) must be the same as input size (torch.Size([1533, 15]))"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_losses = []\n",
    "for epoch in range(10):\n",
    "    progress_bar = tqdm(train_loader, leave=False)\n",
    "    losses = []\n",
    "    total = 0\n",
    "    for inputs, target in progress_bar:\n",
    "        inputs, target = inputs.to(device), target.to(device\n",
    "                                                     )\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(inputs)\n",
    "    \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "              \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        total += 1\n",
    "    \n",
    "    epoch_loss = sum(losses) / total\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f858ba82486940fcbc7bd76d69ac588a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'output'\n",
      "tensor([[ 2.5047e-01, -5.9947e-02,  1.0230e-02, -2.5555e-01, -2.0220e-01,\n",
      "          4.4057e-03,  1.4518e-01,  1.2040e-01,  1.0143e-01, -3.0175e-02,\n",
      "         -5.8386e-02, -1.2564e-02, -1.0053e-02,  7.2277e-02,  2.3042e-01],\n",
      "        [ 2.6239e-01, -4.1282e-02,  8.7380e-02, -1.4541e-01, -1.2756e-01,\n",
      "          7.7238e-02,  4.7882e-02,  1.0111e-01, -8.5092e-02, -1.8413e-02,\n",
      "         -8.0269e-02,  7.3408e-02,  5.9483e-02,  6.3335e-02,  1.3883e-01],\n",
      "        [ 2.9831e-01, -1.4500e-02,  1.3441e-01, -2.7705e-01, -5.7040e-02,\n",
      "          4.7354e-02,  5.2511e-02,  1.1467e-01, -3.0563e-02, -8.4339e-02,\n",
      "         -6.9332e-02,  1.4165e-01,  1.6759e-02,  1.6161e-01,  3.0702e-01],\n",
      "        [ 1.2285e-01, -5.5215e-02,  6.8204e-02, -2.0136e-01, -4.9490e-02,\n",
      "          4.8596e-02,  1.4752e-01,  2.0903e-01, -6.1400e-02,  3.2615e-02,\n",
      "         -1.1471e-01,  2.1627e-02,  6.1680e-02,  4.5400e-02,  2.3308e-01],\n",
      "        [ 2.0266e-01, -1.3471e-02,  9.6764e-02, -2.0628e-01, -1.2545e-01,\n",
      "          2.7798e-02,  6.9826e-02,  1.1654e-01, -3.3361e-02, -2.3571e-02,\n",
      "         -1.4194e-01,  3.9423e-02,  7.8818e-02,  9.3164e-03,  9.5994e-02],\n",
      "        [ 2.0769e-01, -1.6193e-03,  6.6034e-02, -1.6840e-01, -2.4170e-02,\n",
      "          5.1141e-02,  3.2312e-02,  6.2348e-02,  2.0590e-02, -7.8270e-02,\n",
      "         -1.2361e-01,  1.2685e-01,  9.0273e-03,  1.7122e-01,  1.9814e-01],\n",
      "        [ 2.1592e-01,  1.0784e-02,  8.4631e-02, -1.5337e-01, -5.2522e-02,\n",
      "          3.8705e-02,  1.4116e-02,  1.1984e-01,  6.5768e-03, -1.0020e-01,\n",
      "         -1.1513e-01,  1.5778e-01,  1.4160e-02,  1.0477e-01,  2.6235e-01],\n",
      "        [ 2.8372e-01,  1.2317e-02,  2.4411e-02, -1.7531e-01, -1.4664e-01,\n",
      "          1.0344e-01,  6.2288e-02,  6.6182e-02,  3.6515e-02, -5.2169e-02,\n",
      "         -1.0305e-01,  3.3175e-02, -5.0245e-02,  1.0412e-01,  1.6843e-01],\n",
      "        [ 2.1109e-01,  1.4207e-02,  1.0462e-01, -1.9676e-01,  1.0386e-02,\n",
      "          4.6584e-02,  6.2959e-02,  1.1673e-01, -4.2857e-02, -1.1749e-03,\n",
      "         -1.4582e-01,  7.9098e-02,  9.2060e-02,  7.6230e-02,  2.1334e-01],\n",
      "        [ 2.4908e-01, -7.0559e-03,  6.5959e-02, -1.6148e-01, -1.2056e-01,\n",
      "          1.3161e-03, -2.8168e-04,  4.4377e-02,  7.4462e-02, -5.7759e-02,\n",
      "         -9.5102e-02,  1.4581e-01,  2.8986e-02,  9.8087e-02,  1.5831e-01],\n",
      "        [ 2.2614e-01, -1.6679e-02,  9.9888e-02, -1.4051e-01, -1.0156e-01,\n",
      "         -4.3936e-02,  1.2361e-01,  7.8631e-02,  2.1838e-02, -6.9926e-02,\n",
      "         -1.1070e-01,  1.1431e-01,  5.1230e-02,  9.1460e-02,  2.5489e-01],\n",
      "        [ 1.8539e-01, -6.8168e-02,  5.7711e-02, -1.3615e-01, -9.2039e-02,\n",
      "          1.0779e-02,  5.6087e-02,  1.7194e-01, -2.9437e-02, -6.3469e-02,\n",
      "         -9.0307e-02,  7.7580e-02,  6.9554e-02,  9.0414e-02,  1.3599e-01],\n",
      "        [ 2.3182e-01, -4.6009e-02,  4.5663e-02, -1.4311e-01, -8.3406e-02,\n",
      "          6.1005e-02, -9.0816e-02,  5.2930e-02,  6.1348e-02, -2.7226e-02,\n",
      "         -2.8986e-01,  1.4448e-01,  1.2425e-01,  9.5847e-02,  1.9346e-01],\n",
      "        [ 1.9345e-01,  1.8492e-02,  6.7904e-02, -1.7437e-01, -1.2208e-01,\n",
      "          7.6959e-02, -5.2217e-02,  1.0607e-01, -9.3061e-03, -5.2262e-02,\n",
      "         -1.1081e-01,  1.4525e-01,  9.6564e-04,  1.1316e-01,  2.3560e-01],\n",
      "        [ 2.0485e-01, -2.1018e-03,  8.8782e-02, -2.5479e-01, -1.5142e-01,\n",
      "         -2.3473e-02,  8.8067e-02,  1.5890e-01,  8.7486e-02,  1.2986e-02,\n",
      "         -1.1081e-01,  9.5276e-02,  1.2254e-01,  1.5584e-01,  1.9369e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "'target'\n",
      "tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([15])) must be the same as input size (torch.Size([15, 15]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cebb7daba2b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    630\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2580\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([15])) must be the same as input size (torch.Size([15, 15]))"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_losses = []\n",
    "for epoch in range(10):\n",
    "    progress_bar = tqdm(train_loader, leave=False)\n",
    "    losses = []\n",
    "    total = 0\n",
    "    for inputs, target in progress_bar:\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(inputs)\n",
    "        pp.pprint('output')\n",
    "        pp.pprint(output)\n",
    "        pp.pprint('target')\n",
    "        pp.pprint(target)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "              \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        total += 1\n",
    "    \n",
    "    epoch_loss = sum(losses) / total\n",
    "    train_losses.append(epoch_loss)\n",
    "        \n",
    "    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
