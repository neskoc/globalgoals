{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inc import stop_words as sw\n",
    "from inc import extra_stopwords as esw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "table_name = 'Training_set'\n",
    "db_path = 'db/training.sqlite'\n",
    "db_path = 'sqlite:///' + db_path\n",
    "engine = create_engine(db_path, echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-16 19:02:41,939 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-12-16 19:02:41,940 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,942 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-12-16 19:02:41,943 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,945 INFO sqlalchemy.engine.base.Engine SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "2020-12-16 19:02:41,946 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,948 INFO sqlalchemy.engine.base.Engine SELECT name FROM sqlite_master WHERE type='view' ORDER BY name\n",
      "2020-12-16 19:02:41,948 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,950 INFO sqlalchemy.engine.base.Engine PRAGMA main.table_xinfo(\"Training_set\")\n",
      "2020-12-16 19:02:41,951 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,952 INFO sqlalchemy.engine.base.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type = 'table'\n",
      "2020-12-16 19:02:41,953 INFO sqlalchemy.engine.base.Engine ('Training_set',)\n",
      "2020-12-16 19:02:41,955 INFO sqlalchemy.engine.base.Engine PRAGMA main.foreign_key_list(\"Training_set\")\n",
      "2020-12-16 19:02:41,955 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,956 INFO sqlalchemy.engine.base.Engine PRAGMA temp.foreign_key_list(\"Training_set\")\n",
      "2020-12-16 19:02:41,957 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,958 INFO sqlalchemy.engine.base.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type = 'table'\n",
      "2020-12-16 19:02:41,958 INFO sqlalchemy.engine.base.Engine ('Training_set',)\n",
      "2020-12-16 19:02:41,961 INFO sqlalchemy.engine.base.Engine PRAGMA main.index_list(\"Training_set\")\n",
      "2020-12-16 19:02:41,962 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,963 INFO sqlalchemy.engine.base.Engine PRAGMA main.index_info(\"ix_Training_set_index\")\n",
      "2020-12-16 19:02:41,964 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,965 INFO sqlalchemy.engine.base.Engine PRAGMA main.index_list(\"Training_set\")\n",
      "2020-12-16 19:02:41,966 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,967 INFO sqlalchemy.engine.base.Engine PRAGMA main.index_info(\"ix_Training_set_index\")\n",
      "2020-12-16 19:02:41,969 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-12-16 19:02:41,970 INFO sqlalchemy.engine.base.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type = 'table'\n",
      "2020-12-16 19:02:41,971 INFO sqlalchemy.engine.base.Engine ('Training_set',)\n",
      "2020-12-16 19:02:41,977 INFO sqlalchemy.engine.base.OptionEngine SELECT \"Training_set\".\"index\", \"Training_set\".abstract, \"Training_set\".class \n",
      "FROM \"Training_set\"\n",
      "2020-12-16 19:02:41,979 INFO sqlalchemy.engine.base.OptionEngine ()\n"
     ]
    }
   ],
   "source": [
    "training_data_df = pd.read_sql_table(table_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df = training_data_df.rename(columns={\"class\": \"label\"})\n",
    "training_data_df = training_data_df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df = training_data_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-a70bc6488a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4162\u001b[0m         \"\"\"\n\u001b[0;32m-> 4163\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3921\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5282\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "training_data_df = training_data_df.drop(columns=['index'])\n",
    "training_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequences(Dataset):\n",
    "    def __init__(self, df):\n",
    "        sw.STOP_WORDS = sw.STOP_WORDS.union(esw.common_stopwords)\n",
    "        sw.STOP_WORDS = sw.STOP_WORDS.union(esw.extra_stopwords)\n",
    "        self.vectorizer = CountVectorizer(stop_words=sw.STOP_WORDS, max_df=0.99, min_df=0.005)\n",
    "        self.sequences = self.vectorizer.fit_transform(df.abstract.tolist())\n",
    "        self.labels = df.label.tolist()\n",
    "        self.token2idx = self.vectorizer.vocabulary_\n",
    "        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.sequences[i, :].toarray(), self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sequences.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.load('data/' + ID + '.pt')\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2326)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "dataset = Sequences(training_data_df)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "print(dataset[5][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.__getitem__(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(dataset.token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden1, hidden2):\n",
    "        super(BagOfWordsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 15)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BagOfWordsClassifier(\n",
       "  (fc1): Linear(in_features=2326, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BagOfWordsClassifier(len(dataset.token2idx), 128, 64)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543     14\n",
       "1071     8\n",
       "777      4\n",
       "1231    11\n",
       "1125     9\n",
       "        ..\n",
       "1385    16\n",
       "1020     8\n",
       "343     11\n",
       "236      7\n",
       "997      8\n",
       "Name: label, Length: 1533, dtype: Int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_split = np.array_split(training_data_df.label.values, ceil(dim / 15.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 9 has size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-a05e2a43c503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m135\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 9 has size 9"
     ]
    }
   ],
   "source": [
    "stacked = np.vstack(target_split[120:135])\n",
    "pp.pprint(torch.from_numpy(stacked.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1942ee6f64274b51a08b5d4b42b149a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=154.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'output'\n",
      "tensor([[ 9.1280,  7.3236,  6.0056, 13.1826,  8.2901, 10.8844,  7.5277,  8.1969,\n",
      "         10.7310,  6.0438,  7.5591, 12.6305,  8.3105, 14.0736,  8.9967],\n",
      "        [ 6.1685,  4.8066,  4.0866,  8.9273,  5.6747,  6.9252,  5.0936,  5.7102,\n",
      "          7.1163,  3.9768,  5.1489,  8.4046,  5.4390,  9.4187,  5.9548],\n",
      "        [ 5.1794,  4.2525,  3.5261,  7.6678,  4.7623,  6.0590,  4.3582,  5.0220,\n",
      "          6.2190,  3.5486,  4.2973,  7.3956,  4.6648,  8.1004,  5.1877],\n",
      "        [ 4.7989,  3.6091,  3.0985,  6.7967,  4.3190,  5.3443,  3.8441,  4.3850,\n",
      "          5.4253,  3.1233,  3.8732,  6.4106,  4.1051,  7.2005,  4.5874],\n",
      "        [ 3.3698,  2.6143,  2.1912,  4.8741,  3.1303,  3.7373,  2.7667,  3.2799,\n",
      "          3.8731,  2.2212,  2.7647,  4.6519,  2.8758,  5.0448,  3.3468],\n",
      "        [ 2.9508,  2.2373,  1.9330,  4.1141,  2.5419,  3.2365,  2.3572,  2.7965,\n",
      "          3.3477,  1.9336,  2.3421,  3.8981,  2.4515,  4.3540,  2.7688],\n",
      "        [ 5.1577,  3.8503,  3.3644,  7.2520,  4.6435,  5.8587,  3.8661,  4.6651,\n",
      "          5.8383,  3.2726,  4.1058,  6.9855,  4.4523,  7.7275,  4.8845],\n",
      "        [ 4.8172,  3.8382,  3.2190,  6.9405,  4.2831,  5.7066,  3.9167,  4.5877,\n",
      "          5.7698,  3.4148,  3.7983,  6.8258,  4.2859,  7.4873,  4.8723],\n",
      "        [ 4.6005,  3.5310,  2.9857,  6.5499,  4.0850,  5.2361,  3.7110,  4.2914,\n",
      "          5.3274,  3.1114,  3.6265,  6.3452,  3.9481,  6.9121,  4.5702],\n",
      "        [ 4.5215,  3.6055,  2.9029,  6.5626,  3.9737,  5.1281,  3.6509,  4.3265,\n",
      "          5.1946,  3.0496,  3.7025,  6.3041,  3.8432,  6.8222,  4.3506]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "count: 0 target\n",
      "tensor([[ 7.,  7.,  6.,  6.,  6., 11.,  3., 10., 14.,  3., 14., 17.,  2.,  2.,\n",
      "          2.],\n",
      "        [ 2.,  2., 16.,  3., 17., 15., 15., 10., 16., 13., 13.,  9., 11., 17.,\n",
      "          9.],\n",
      "        [ 7., 10.,  2.,  3.,  6., 17., 11., 15.,  3.,  7.,  3.,  3., 14., 17.,\n",
      "         12.],\n",
      "        [10., 16., 12., 17.,  4., 13.,  8.,  7., 16., 14.,  7.,  7.,  6.,  6.,\n",
      "          4.],\n",
      "        [10.,  8., 14., 16., 10., 12., 10., 10., 17., 11.,  6., 11., 13.,  4.,\n",
      "          3.],\n",
      "        [17., 16., 10., 14.,  5., 14., 17.,  3., 14., 10., 13.,  2.,  3., 13.,\n",
      "          9.],\n",
      "        [ 6., 13., 14.,  2.,  3.,  9.,  4., 11.,  9., 16.,  2., 15., 17.,  5.,\n",
      "          9.],\n",
      "        [15.,  7.,  9.,  3.,  8.,  5., 12., 16., 14.,  8., 16.,  9.,  4., 10.,\n",
      "          8.],\n",
      "        [ 3., 12., 13.,  9.,  7., 16., 17.,  6., 15., 15., 12.,  8.,  2., 11.,\n",
      "          9.],\n",
      "        [ 3., 15.,  3.,  7.,  7.,  3., 17.,  7., 10., 17.,  8., 13., 14.,  6.,\n",
      "         11.]], dtype=torch.float64)\n",
      "'output'\n",
      "tensor([[ 4.6529,  3.7016,  3.1408,  6.7524,  4.2074,  5.2860,  3.8164,  4.4463,\n",
      "          5.4434,  3.0918,  3.8823,  6.4051,  4.1427,  6.9851,  4.5142],\n",
      "        [ 7.3358,  5.8750,  4.8008, 10.5301,  6.5724,  8.5094,  6.0189,  6.7601,\n",
      "          8.5073,  4.9628,  6.0965, 10.0656,  6.4633, 11.1189,  7.1637],\n",
      "        [ 4.8769,  3.8180,  3.1942,  6.9214,  4.3947,  5.6631,  3.9829,  4.5932,\n",
      "          5.6127,  3.1947,  3.9511,  6.6510,  4.3134,  7.2719,  4.8080],\n",
      "        [ 4.6960,  3.7749,  3.0731,  6.7902,  4.1075,  5.4154,  3.8169,  4.5503,\n",
      "          5.4381,  3.2654,  3.8803,  6.4820,  4.1247,  6.9787,  4.6691],\n",
      "        [ 5.2401,  4.0965,  3.3802,  7.3871,  4.6550,  5.9877,  4.2045,  4.9454,\n",
      "          6.0110,  3.4626,  4.2531,  7.1352,  4.5680,  7.7384,  5.1330],\n",
      "        [ 4.3999,  3.5739,  2.9440,  6.3272,  3.8849,  5.1122,  3.6082,  4.1657,\n",
      "          5.1299,  2.9548,  3.5001,  6.1402,  3.8779,  6.6106,  4.2593],\n",
      "        [ 5.2311,  4.3286,  3.4056,  7.5223,  4.7156,  6.0802,  4.3242,  4.9743,\n",
      "          6.1779,  3.4692,  4.4677,  7.1822,  4.6671,  7.8369,  5.2629],\n",
      "        [ 9.1122,  7.3101,  6.0941, 13.1835,  8.1433, 10.5672,  7.6503,  8.4027,\n",
      "         10.7467,  5.9402,  7.4361, 12.5803,  8.2096, 13.7328,  9.0661],\n",
      "        [ 4.6283,  3.5359,  3.0421,  6.4638,  4.2054,  5.3057,  3.7114,  4.2250,\n",
      "          5.1401,  2.9923,  3.7779,  6.1750,  3.9662,  6.8841,  4.3535],\n",
      "        [ 7.0259,  5.7152,  4.6291, 10.1502,  6.2885,  8.2066,  5.7806,  6.5886,\n",
      "          8.2776,  4.7679,  5.7078,  9.7839,  6.2539, 10.6998,  6.9603]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "count: 1 target\n",
      "tensor([[14.,  8.,  6.,  7., 15., 17.,  9., 16., 15.,  7.,  6., 10., 14., 14.,\n",
      "         12.],\n",
      "        [ 8.,  9., 16.,  8., 14., 12., 16., 10.,  2.,  3., 13.,  2., 15., 17.,\n",
      "         14.],\n",
      "        [ 4., 16., 17.,  6.,  7.,  2., 10.,  6.,  5.,  7., 10., 16., 13.,  2.,\n",
      "          3.],\n",
      "        [11.,  4.,  2., 14., 16.,  2., 14., 15., 16., 17., 10.,  3.,  9.,  8.,\n",
      "         13.],\n",
      "        [ 9.,  8.,  4., 14., 17.,  3., 17., 10., 10., 13.,  8.,  3., 12.,  5.,\n",
      "         13.],\n",
      "        [12.,  6., 15.,  7., 17., 12.,  6.,  8., 15., 11., 13., 11., 13., 15.,\n",
      "          4.],\n",
      "        [10., 11., 15., 12., 14., 10.,  7.,  9.,  6., 11.,  4., 16.,  6.,  2.,\n",
      "         11.],\n",
      "        [ 4.,  3., 15.,  7.,  8., 16., 13., 16.,  6., 16.,  7., 14., 16., 11.,\n",
      "          6.],\n",
      "        [16.,  8., 12.,  9.,  9., 16.,  9., 10.,  6., 11.,  5.,  9., 15.,  5.,\n",
      "         11.],\n",
      "        [ 6., 16.,  3., 14.,  8.,  2.,  8., 12., 11., 11.,  7., 17.,  3.,  9.,\n",
      "          4.]], dtype=torch.float64)\n",
      "'output'\n",
      "tensor([[ 3.2458,  2.5371,  2.2038,  4.5888,  2.8940,  3.6597,  2.7121,  3.1224,\n",
      "          3.6503,  2.1567,  2.6928,  4.3582,  2.8487,  4.6771,  3.1110],\n",
      "        [ 3.6282,  2.8208,  2.3807,  5.0379,  3.2244,  4.1060,  2.9322,  3.3767,\n",
      "          4.0352,  2.3877,  2.8648,  4.8644,  3.1589,  5.2473,  3.4701],\n",
      "        [ 7.8205,  6.2534,  5.1143, 11.0458,  6.8550,  8.8729,  6.4505,  7.2554,\n",
      "          8.9486,  5.1305,  6.4699, 10.5524,  6.8853, 11.3313,  7.7050],\n",
      "        [ 5.0766,  4.1098,  3.3993,  7.2349,  4.5155,  5.6257,  4.2295,  4.7818,\n",
      "          5.7859,  3.3111,  4.2883,  6.8033,  4.5011,  7.3827,  4.8686],\n",
      "        [ 4.2213,  3.3997,  2.8130,  5.9732,  3.7759,  4.8031,  3.5235,  4.0099,\n",
      "          4.8447,  2.8999,  3.4390,  5.7700,  3.6975,  6.2046,  4.1802],\n",
      "        [ 9.2384,  7.7279,  6.3453, 13.4356,  8.2916, 10.9210,  7.7641,  8.7368,\n",
      "         10.9441,  6.4516,  7.7545, 13.0169,  8.2631, 14.0274,  9.2664],\n",
      "        [ 5.4676,  4.3806,  3.6128,  7.8054,  4.9244,  6.2268,  4.5522,  5.2050,\n",
      "          6.3239,  3.6802,  4.4513,  7.5609,  4.8407,  8.0954,  5.4345],\n",
      "        [ 7.0173,  5.6650,  4.6206,  9.9780,  6.1704,  8.0610,  5.7567,  6.5196,\n",
      "          8.0575,  4.7430,  5.7156,  9.6095,  6.0833, 10.3333,  6.8775],\n",
      "        [ 5.7144,  4.5458,  3.8196,  8.1408,  5.0774,  6.5739,  4.6755,  5.3743,\n",
      "          6.5622,  3.7968,  4.6444,  7.8311,  5.0739,  8.3764,  5.6031],\n",
      "        [12.8420, 10.4357,  8.4392, 18.3905, 11.4080, 14.8776, 10.5752, 11.9342,\n",
      "         14.8078,  8.6385, 10.6514, 17.5823, 11.2956, 19.1445, 12.6143]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "count: 2 target\n",
      "tensor([[ 9.,  9., 14.,  4.,  9., 15., 13., 13., 16., 11., 13., 15., 10.,  6.,\n",
      "          7.],\n",
      "        [13.,  4., 17.,  6.,  6., 10., 14.,  2.,  8., 11., 13., 15., 16., 17.,\n",
      "         10.],\n",
      "        [14.,  5., 10., 16.,  9., 12.,  7., 16.,  3., 12.,  2.,  6., 12., 17.,\n",
      "         11.],\n",
      "        [ 9.,  8., 13., 17.,  5., 10., 17., 15.,  2., 10.,  3., 15., 17.,  9.,\n",
      "          2.],\n",
      "        [15., 13., 11.,  4., 10., 10.,  4.,  3.,  7., 13., 11.,  8., 13.,  6.,\n",
      "          8.],\n",
      "        [17., 17.,  9.,  2.,  2.,  7.,  6.,  7., 16.,  3.,  8., 17., 15., 15.,\n",
      "          5.],\n",
      "        [ 4., 12.,  8.,  7.,  5., 10., 12.,  5.,  7.,  4., 17.,  2.,  8., 13.,\n",
      "         17.],\n",
      "        [12.,  6., 13., 16.,  2., 10., 10.,  9., 12.,  6.,  2.,  2., 11.,  7.,\n",
      "         10.],\n",
      "        [ 6.,  4., 15.,  8., 14., 16.,  9.,  6.,  2.,  3., 14.,  2., 11., 17.,\n",
      "          9.],\n",
      "        [13.,  6., 12.,  5., 16.,  2.,  9., 12.,  9., 12., 10., 10., 17., 11.,\n",
      "          7.]], dtype=torch.float64)\n",
      "'output'\n",
      "tensor([[ 4.6456,  3.6960,  3.1681,  6.5305,  4.1047,  5.1494,  3.9125,  4.3474,\n",
      "          5.1927,  3.0635,  3.8310,  6.1985,  4.0507,  6.6226,  4.4244],\n",
      "        [17.4745, 14.7325, 11.6560, 25.2229, 15.8683, 20.5327, 14.6848, 16.5328,\n",
      "         20.3413, 12.1113, 14.8711, 24.3152, 15.5651, 26.1156, 17.4796],\n",
      "        [25.7172, 21.4147, 17.1739, 37.1161, 23.2957, 30.0874, 21.7549, 24.2074,\n",
      "         29.8890, 17.3093, 21.3423, 35.8074, 23.1273, 38.0814, 25.8857],\n",
      "        [ 5.6089,  4.4462,  3.7029,  7.8844,  4.9864,  6.3654,  4.5924,  5.3730,\n",
      "          6.3704,  3.7667,  4.6155,  7.5854,  4.8738,  8.1017,  5.4614],\n",
      "        [ 9.9136,  8.0707,  6.5923, 13.9726,  8.9199, 11.4040,  8.2224,  9.1337,\n",
      "         11.1935,  6.5204,  8.3796, 13.3518,  8.7636, 14.4863,  9.6666],\n",
      "        [ 2.9344,  2.2956,  1.9666,  4.0469,  2.5235,  3.2329,  2.3885,  2.8391,\n",
      "          3.2696,  1.9507,  2.3303,  3.8966,  2.5419,  4.0869,  2.8280],\n",
      "        [ 4.9955,  4.0552,  3.3283,  6.9990,  4.3759,  5.6512,  4.1826,  4.6980,\n",
      "          5.6771,  3.3535,  4.1195,  6.7118,  4.3684,  7.2218,  4.9023],\n",
      "        [ 4.2109,  3.3369,  2.7964,  5.8584,  3.7116,  4.6483,  3.4755,  4.0126,\n",
      "          4.7086,  2.8025,  3.5154,  5.5924,  3.6250,  6.0026,  4.0728],\n",
      "        [24.7667, 20.5653, 16.5223, 35.5474, 22.2948, 29.0828, 20.5950, 23.3067,\n",
      "         28.7054, 16.8767, 20.7052, 34.2868, 22.1293, 36.7163, 24.8188],\n",
      "        [ 2.5596,  1.9330,  1.7155,  3.4673,  2.2308,  2.8377,  2.0426,  2.4421,\n",
      "          2.7951,  1.6719,  2.0113,  3.3737,  2.2001,  3.5746,  2.3811]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "count: 3 target\n",
      "tensor([[ 8., 11., 12., 13., 17., 13.,  9.,  3., 17.,  6., 14., 15., 15.,  6.,\n",
      "          2.],\n",
      "        [ 8.,  4.,  4., 11., 16., 17., 16.,  7.,  7., 14.,  3., 17.,  3.,  6.,\n",
      "         16.],\n",
      "        [17.,  3., 16., 11.,  2.,  6.,  2., 15.,  7.,  5.,  9.,  8., 14.,  4.,\n",
      "          6.],\n",
      "        [ 8., 17.,  5., 16., 12.,  4.,  8.,  9., 16.,  5., 17., 12., 17.,  3.,\n",
      "         11.],\n",
      "        [11., 11., 10.,  8.,  8., 16., 14., 10.,  8., 15., 11., 15., 12.,  3.,\n",
      "          9.],\n",
      "        [ 4., 13., 14.,  4.,  9., 15.,  7.,  9., 17., 11.,  4., 16., 16., 15.,\n",
      "         12.],\n",
      "        [10.,  5., 11.,  3.,  8.,  2., 13.,  5.,  2., 13.,  2., 16., 13.,  2.,\n",
      "         12.],\n",
      "        [ 4., 11.,  8.,  9.,  6., 16., 10., 13., 10.,  3., 14., 15.,  5.,  7.,\n",
      "          2.],\n",
      "        [10.,  4., 15.,  9.,  8.,  8., 14., 12., 14.,  9.,  2., 16.,  5., 14.,\n",
      "          2.],\n",
      "        [ 3.,  3.,  5.,  8.,  9., 14.,  9., 17., 16.,  9., 14., 12.,  3., 13.,\n",
      "         10.]], dtype=torch.float64)\n",
      "'output'\n",
      "tensor([[ 6.2671,  5.0999,  4.1698,  8.8546,  5.5833,  6.9856,  5.2512,  5.9919,\n",
      "          7.0014,  4.1954,  5.2798,  8.4363,  5.5109,  8.9005,  6.1044],\n",
      "        [ 6.7412,  5.5029,  4.4579,  9.4596,  5.9522,  7.6335,  5.6327,  6.3925,\n",
      "          7.5994,  4.4896,  5.5729,  9.0930,  5.8867,  9.5846,  6.6220],\n",
      "        [ 3.4321,  2.7629,  2.2858,  4.7365,  3.0392,  3.8277,  2.8619,  3.2891,\n",
      "          3.7793,  2.2524,  2.8367,  4.5415,  2.9675,  4.7748,  3.3332],\n",
      "        [ 9.6315,  7.9111,  6.4121, 13.6012,  8.6559, 10.9935,  8.0771,  9.1186,\n",
      "         10.8995,  6.4643,  8.1284, 13.0213,  8.5083, 13.9010,  9.5247],\n",
      "        [ 6.6443,  5.5573,  4.4280,  9.3792,  5.8006,  7.5909,  5.5698,  6.3483,\n",
      "          7.5952,  4.6593,  5.5485,  9.0520,  5.8098,  9.5676,  6.5912],\n",
      "        [11.1259,  9.2323,  7.4194, 15.7323,  9.8188, 12.8327,  9.0969, 10.5156,\n",
      "         12.5629,  7.7193,  9.3196, 15.1062,  9.6942, 16.1868, 10.8526],\n",
      "        [ 6.0979,  4.9740,  4.0501,  8.5349,  5.3696,  6.8377,  5.0877,  5.7744,\n",
      "          6.7895,  4.1513,  5.0573,  8.1138,  5.2535,  8.6507,  5.9557],\n",
      "        [ 7.6777,  6.3188,  5.2370, 10.8347,  6.8989,  8.7715,  6.4972,  7.2556,\n",
      "          8.7375,  5.2042,  6.5288, 10.3816,  6.8115, 11.0778,  7.5380],\n",
      "        [ 7.9021,  6.4575,  5.2089, 11.0552,  6.8830,  8.9512,  6.5368,  7.4728,\n",
      "          8.8293,  5.3200,  6.4926, 10.6579,  6.8741, 11.2258,  7.7300],\n",
      "        [ 7.1290,  5.8248,  4.7020, 10.0301,  6.4165,  8.1494,  5.9727,  6.6987,\n",
      "          7.9985,  4.8401,  5.8778,  9.6792,  6.2948, 10.2552,  7.0272]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "count: 4 target\n",
      "tensor([[ 8.,  4.,  8., 16., 15.,  2., 10., 15., 10.,  7.,  2., 11., 11.,  3.,\n",
      "          7.],\n",
      "        [ 2., 10., 10., 15., 10., 17., 10., 10.,  8., 17.,  3.,  3.,  8., 13.,\n",
      "          3.],\n",
      "        [12., 10.,  9.,  7., 13.,  9.,  7., 16.,  6., 10., 10., 13., 13.,  9.,\n",
      "         15.],\n",
      "        [16.,  9.,  3.,  4., 11.,  4.,  4., 14.,  4., 17.,  4., 17.,  5., 12.,\n",
      "          6.],\n",
      "        [17., 12., 15., 13., 16., 13., 12., 15.,  7.,  6.,  7., 15., 11., 13.,\n",
      "          2.],\n",
      "        [ 8., 12., 17., 10., 12., 17., 12., 14., 11., 11.,  8., 16.,  4.,  2.,\n",
      "         17.],\n",
      "        [10.,  4.,  4., 13., 13.,  7.,  3.,  4.,  6., 13.,  8.,  9.,  3.,  2.,\n",
      "          5.],\n",
      "        [17., 10., 10., 10., 10.,  2., 11.,  4.,  8., 16., 10., 11.,  2.,  4.,\n",
      "         17.],\n",
      "        [15., 16., 16., 13., 16., 16.,  3.,  6.,  6., 16., 12.,  2., 14., 11.,\n",
      "         14.],\n",
      "        [14.,  7.,  2.,  3.,  2.,  6.,  8., 11., 13.,  9.,  9., 12.,  8.,  7.,\n",
      "          2.]], dtype=torch.float64)\n",
      "'output'\n",
      "tensor([[ 9.4278,  7.7976,  6.1870, 13.1091,  8.3361, 10.5772,  7.9338,  8.8039,\n",
      "         10.4694,  6.3436,  7.9372, 12.5495,  8.1979, 13.2331,  9.2331],\n",
      "        [ 7.2353,  5.9933,  4.7616, 10.0534,  6.3294,  8.1431,  6.0467,  6.8064,\n",
      "          8.0796,  4.8760,  6.0494,  9.6743,  6.2962, 10.1581,  7.1328],\n",
      "        [ 6.4487,  5.2831,  4.4470,  9.0779,  5.8339,  7.2869,  5.5106,  6.2305,\n",
      "          7.2582,  4.5086,  5.4395,  8.6930,  5.6834,  9.2104,  6.3357],\n",
      "        [11.7102,  9.6140,  7.6971, 16.3513, 10.3678, 13.2039,  9.7630, 11.0552,\n",
      "         13.0586,  7.8640,  9.7638, 15.7096, 10.2100, 16.4664, 11.5777],\n",
      "        [ 7.2099,  5.9861,  4.8235, 10.0483,  6.4058,  8.1506,  6.0545,  6.8329,\n",
      "          8.0727,  4.9243,  6.0989,  9.6401,  6.3843, 10.1836,  7.1384],\n",
      "        [ 8.4805,  6.8677,  5.6642, 11.8291,  7.5127,  9.5463,  7.0610,  7.9919,\n",
      "          9.4529,  5.6160,  7.0393, 11.3557,  7.3071, 11.9173,  8.2394],\n",
      "        [ 8.7563,  7.2578,  5.8512, 12.3123,  7.7408,  9.9277,  7.2901,  8.3740,\n",
      "          9.8409,  6.0065,  7.3205, 11.8096,  7.6698, 12.3943,  8.6362],\n",
      "        [ 8.7758,  7.2395,  5.8524, 12.1894,  7.6975,  9.9080,  7.3099,  8.2296,\n",
      "          9.7630,  5.9374,  7.3613, 11.7241,  7.6369, 12.3539,  8.5495],\n",
      "        [ 7.0338,  5.8791,  4.7166,  9.8099,  6.2496,  7.9123,  5.8951,  6.7035,\n",
      "          7.9410,  4.8318,  5.9912,  9.4486,  6.1551,  9.9658,  6.9349],\n",
      "        [ 7.2678,  5.9704,  4.8597, 10.0652,  6.3274,  8.0981,  6.0803,  6.7980,\n",
      "          8.1082,  4.9444,  6.0564,  9.6501,  6.3591, 10.2043,  7.0507]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "count: 5 target\n",
      "tensor([[ 5.,  8.,  3., 10., 11.,  2., 14., 17.,  7., 12., 17., 12.,  4., 10.,\n",
      "          6.],\n",
      "        [15., 17., 13., 17., 12., 12., 10., 13., 14.,  8.,  2., 13., 16.,  8.,\n",
      "         11.],\n",
      "        [ 2., 12.,  9., 17., 13.,  8., 15.,  6.,  6., 11.,  7., 14., 10.,  6.,\n",
      "          9.],\n",
      "        [11., 15.,  2.,  7.,  9., 16., 12.,  9.,  5., 17.,  2.,  8., 10., 16.,\n",
      "         16.],\n",
      "        [ 7., 13.,  7.,  3., 11., 14., 14., 10., 14.,  9.,  5., 14., 12.,  2.,\n",
      "          4.],\n",
      "        [12., 11., 12.,  9., 14.,  9.,  6.,  9., 13., 15.,  4., 11.,  2., 14.,\n",
      "         13.],\n",
      "        [12., 12., 15.,  7., 12.,  4.,  9.,  8.,  6.,  8.,  4.,  3.,  2.,  2.,\n",
      "          8.],\n",
      "        [ 8., 15., 17.,  7., 15., 13., 16.,  9.,  9., 12., 12.,  5., 12., 13.,\n",
      "          4.],\n",
      "        [ 6., 13., 14., 10., 17., 16., 15., 13., 15., 14., 15., 14., 13., 13.,\n",
      "         11.],\n",
      "        [ 7.,  7., 12., 14.,  3., 11.,  2.,  2., 14.,  8.,  5., 11.,  6., 14.,\n",
      "         11.]], dtype=torch.float64)\n",
      "'output'\n",
      "tensor([[ 5.9249,  4.9407,  4.0527,  8.2188,  5.2264,  6.6393,  4.9875,  5.7518,\n",
      "          6.6676,  4.1425,  5.0747,  7.8957,  5.1481,  8.2597,  5.8608],\n",
      "        [11.1869,  9.2756,  7.5752, 15.4660,  9.9689, 12.6423,  9.4992, 10.5436,\n",
      "         12.4950,  7.6880,  9.4381, 14.8691,  9.8627, 15.7072, 11.0437],\n",
      "        [10.1993,  8.5592,  6.7865, 14.1638,  8.9616, 11.4865,  8.6454,  9.6501,\n",
      "         11.2931,  6.9887,  8.6570, 13.5161,  8.9091, 14.2195,  9.9879],\n",
      "        [ 6.0141,  5.0124,  4.0848,  8.3515,  5.3061,  6.7449,  5.0992,  5.7266,\n",
      "          6.6310,  4.1160,  5.1286,  7.9765,  5.2869,  8.3244,  5.8428],\n",
      "        [ 4.9439,  4.0199,  3.2841,  6.7080,  4.2973,  5.4985,  4.0680,  4.6533,\n",
      "          5.3726,  3.3892,  4.0496,  6.4678,  4.2525,  6.7809,  4.7550],\n",
      "        [ 6.9764,  5.7543,  4.6426,  9.5565,  6.0816,  7.7347,  5.8429,  6.5474,\n",
      "          7.6529,  4.6458,  5.8283,  9.1840,  6.0756,  9.5626,  6.7538],\n",
      "        [ 6.8151,  5.6010,  4.5722,  9.3706,  5.9583,  7.5137,  5.7034,  6.4619,\n",
      "          7.4804,  4.6313,  5.7416,  8.9607,  5.8874,  9.3836,  6.6077],\n",
      "        [10.2534,  8.4248,  6.7671, 14.1132,  9.0294, 11.4297,  8.4909,  9.6244,\n",
      "         11.2444,  6.8548,  8.6337, 13.5660,  8.9652, 14.1724,  9.9724],\n",
      "        [ 8.2983,  6.8343,  5.5193, 11.3887,  7.3123,  9.2696,  6.9025,  7.7582,\n",
      "          9.0711,  5.5679,  7.0182, 10.9089,  7.1962, 11.5045,  8.0734],\n",
      "        [ 5.7064,  4.6905,  3.8833,  7.8786,  5.0809,  6.3519,  4.8462,  5.4102,\n",
      "          6.3191,  3.9498,  4.8213,  7.5208,  4.9951,  7.9187,  5.5829]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "count: 6 target\n",
      "tensor([[ 8., 15.,  2.,  8., 16.,  3.,  8.,  3.,  6.,  6., 17., 14., 11., 12.,\n",
      "         12.],\n",
      "        [10.,  6.,  5.,  9., 12.,  9., 12., 11.,  9.,  9.,  7., 17., 15.,  4.,\n",
      "          5.],\n",
      "        [ 8.,  2., 14., 15., 13.,  3., 10., 12., 11., 17., 10., 12., 17., 15.,\n",
      "          8.],\n",
      "        [14.,  6.,  3.,  3.,  3.,  3., 16., 15.,  2.,  3.,  4.,  9., 13.,  5.,\n",
      "         13.],\n",
      "        [ 9., 11., 12.,  6.,  4.,  6.,  5., 12., 14.,  7., 15.,  9., 14.,  9.,\n",
      "          6.],\n",
      "        [13.,  3.,  4., 10.,  9.,  7.,  5.,  4., 16.,  5.,  6.,  3., 15., 16.,\n",
      "         10.],\n",
      "        [ 9., 16., 13., 12., 15., 14.,  8.,  7.,  5., 15.,  7., 14.,  4.,  4.,\n",
      "         13.],\n",
      "        [12.,  7., 15., 10., 11., 17., 14., 15.,  3.,  4., 14.,  7.,  5., 14.,\n",
      "         12.],\n",
      "        [10., 17.,  9., 10.,  5.,  8.,  2.,  6., 13., 10., 16.,  7., 16., 15.,\n",
      "          6.],\n",
      "        [14.,  8.,  4., 13.,  5.,  3., 14.,  6., 15., 11.,  8., 13., 14., 12.,\n",
      "         13.]], dtype=torch.float64)\n",
      "'output'\n",
      "tensor([[ 7.4997,  6.2252,  5.0922, 10.3598,  6.7001,  8.4445,  6.3294,  7.1283,\n",
      "          8.2258,  5.1610,  6.3517,  9.9431,  6.5255, 10.4071,  7.3053],\n",
      "        [ 6.6264,  5.5625,  4.4651,  9.0314,  5.8164,  7.3673,  5.5819,  6.2939,\n",
      "          7.2643,  4.5489,  5.6339,  8.6747,  5.7784,  9.0890,  6.4574],\n",
      "        [10.8052,  9.0761,  7.2643, 14.8992,  9.5036, 12.0570,  9.1297, 10.1755,\n",
      "         11.8013,  7.3440,  9.2269, 14.2141,  9.4059, 14.8277, 10.4666],\n",
      "        [ 7.8833,  6.6990,  5.2753, 10.8270,  6.8956,  8.8129,  6.6068,  7.4536,\n",
      "          8.5982,  5.4397,  6.6544, 10.4403,  6.7982, 10.7784,  7.6390],\n",
      "        [ 7.7108,  6.4378,  5.2518, 10.5559,  6.8202,  8.5913,  6.5473,  7.2555,\n",
      "          8.4481,  5.3102,  6.5776, 10.1122,  6.7006, 10.6401,  7.4904],\n",
      "        [12.3455, 10.3555,  8.2861, 16.9818, 10.8958, 13.7851, 10.4536, 11.6266,\n",
      "         13.5644,  8.3924, 10.5928, 16.2803, 10.7551, 16.9967, 12.0412],\n",
      "        [ 9.0010,  7.5716,  6.0688, 12.4208,  8.0074, 10.0968,  7.6255,  8.4117,\n",
      "          9.8443,  6.0809,  7.6629, 11.9080,  7.8804, 12.3751,  8.7642],\n",
      "        [ 8.7914,  7.3875,  5.9768, 12.1250,  7.8178,  9.8051,  7.5235,  8.3255,\n",
      "          9.6672,  6.0416,  7.5773, 11.5482,  7.6669, 12.1712,  8.5790],\n",
      "        [11.7462,  9.9691,  8.0134, 16.2609, 10.3756, 13.2943, 10.0487, 11.1525,\n",
      "         13.1646,  8.1996,  9.9391, 15.6745, 10.3933, 16.3349, 11.6321],\n",
      "        [ 8.4112,  7.0959,  5.5459, 11.4836,  7.3323,  9.2697,  7.1547,  7.8944,\n",
      "          9.2093,  5.7396,  7.1442, 11.0338,  7.3490, 11.4497,  8.2483]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "count: 7 target\n",
      "tensor([[ 2.,  7., 16., 15., 15., 16.,  2., 17.,  9.,  8., 15.,  6.,  4., 11.,\n",
      "         15.],\n",
      "        [ 7., 15., 10.,  4.,  9., 13., 16.,  7., 17., 12., 13.,  2., 11., 16.,\n",
      "          2.],\n",
      "        [11.,  8.,  7.,  4.,  5., 12.,  9.,  2.,  9., 11.,  8.,  2.,  3.,  3.,\n",
      "         11.],\n",
      "        [ 3.,  8.,  6., 10.,  5., 15., 17., 13., 16., 15., 10.,  7.,  8.,  4.,\n",
      "          7.],\n",
      "        [12., 15.,  4., 13.,  3.,  2.,  2., 15.,  4., 16.,  7., 11.,  6.,  6.,\n",
      "         17.],\n",
      "        [15., 11., 10., 15., 14., 10.,  3.,  7., 12., 12.,  7., 13., 15.,  9.,\n",
      "          8.],\n",
      "        [ 7.,  8.,  8., 14.,  9., 14., 13., 12., 17.,  2., 15., 14., 11.,  5.,\n",
      "         13.],\n",
      "        [ 4., 14.,  2.,  8.,  4.,  8.,  4., 16.,  2., 12.,  6., 14., 17., 12.,\n",
      "         14.],\n",
      "        [16., 17., 17., 11.,  5., 17., 14.,  7., 12.,  3., 16., 17.,  3., 13.,\n",
      "          3.],\n",
      "        [ 6.,  3.,  3.,  5., 12.,  4.,  9., 12., 15.,  7.,  4.,  6.,  8.,  3.,\n",
      "         16.]], dtype=torch.float64)\n",
      "'output'\n",
      "tensor([[ 7.5249,  6.3548,  5.1493, 10.3268,  6.6362,  8.3382,  6.4233,  7.1822,\n",
      "          8.2745,  5.2121,  6.4323,  9.9241,  6.5060, 10.3104,  7.3163],\n",
      "        [ 7.8335,  6.5682,  5.2531, 10.6850,  6.8938,  8.6854,  6.6345,  7.4181,\n",
      "          8.4864,  5.3641,  6.6767, 10.2310,  6.7495, 10.6114,  7.6039],\n",
      "        [ 8.4036,  7.0781,  5.6896, 11.4891,  7.4196,  9.3070,  7.1818,  7.9397,\n",
      "          9.1456,  5.7542,  7.1891, 11.0250,  7.2562, 11.4108,  8.2016],\n",
      "        [ 9.0298,  7.5655,  6.0844, 12.3664,  7.9800,  9.9963,  7.6221,  8.5514,\n",
      "          9.7978,  6.2034,  7.6965, 11.8167,  7.8043, 12.2527,  8.8446],\n",
      "        [12.7563, 10.8308,  8.6784, 17.6260, 11.3425, 14.4027, 10.9158, 12.0701,\n",
      "         14.0123,  8.8503, 10.9672, 16.9191, 11.2064, 17.5630, 12.5805],\n",
      "        [ 5.2581,  4.3760,  3.5748,  7.1082,  4.5514,  5.7758,  4.4477,  4.9566,\n",
      "          5.6415,  3.5865,  4.4195,  6.7947,  4.5014,  7.0491,  5.0302],\n",
      "        [ 5.6023,  4.6901,  3.8268,  7.6448,  4.9300,  6.1891,  4.7723,  5.3145,\n",
      "          6.0515,  3.8534,  4.7349,  7.3111,  4.8310,  7.5708,  5.3931],\n",
      "        [ 5.3315,  4.4385,  3.5959,  7.2023,  4.6349,  5.8717,  4.4753,  5.0189,\n",
      "          5.7281,  3.6322,  4.4818,  6.9273,  4.5794,  7.1511,  5.1442],\n",
      "        [ 9.7757,  8.2980,  6.5848, 13.4325,  8.6195, 10.9107,  8.3083,  9.3121,\n",
      "         10.7234,  6.7878,  8.3209, 12.9250,  8.4751, 13.3615,  9.6192],\n",
      "        [18.7254, 16.1472, 12.8468, 26.0479, 16.7534, 21.2282, 16.1291, 17.8300,\n",
      "         20.8133, 13.1125, 16.3036, 25.0000, 16.5191, 26.0003, 18.6014]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-88ad35f87ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_losses = []\n",
    "for epoch in range(10):\n",
    "    progress_bar = tqdm(train_loader, leave=False)\n",
    "    losses = []\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for inputs, target in progress_bar:\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(inputs)\n",
    "        pp.pprint('output')\n",
    "        pp.pprint(output)\n",
    "        \n",
    "        stacked = np.stack(target_split[15*count:15*(count+1)])\n",
    "        print(' target')\n",
    "        stacked = stacked.T\n",
    "        pp.pprint(target_batch)\n",
    "        target_batch = torch.from_numpy(stacked.astype(float))\n",
    "        count += 1\n",
    "        \n",
    "        loss = criterion(output, target_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "              \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        total += 1\n",
    "    \n",
    "    epoch_loss = sum(losses) / total\n",
    "    train_losses.append(epoch_loss)\n",
    "        \n",
    "    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
